{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn2DQ0skh_k2"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# **Rob Boswell**\n",
        "\n",
        "# **Portfolio Project:** \"Sequential RNN Text Classification Models for Twitter COVID-19 Misinformation Detection\"\n",
        "\n",
        "# **Models Originally Created:** Apr 18, 2021\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1kQ3w_Yk8Ib"
      },
      "source": [
        "### **Data Source:**  Shahi, Gautam Kishore, Anne Dirkson, and Tim A. Majchrzak. \"An exploratory study of covid-19 misinformation on twitter.\" Online Social Networks and Media 22 (2021): 100104."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the twitter dataset from Shahi et al (2021) that was created during the midst of the COVID-19 pandemic, I created deep learning models for sequential data which used embedding layers, Long Short-Term Memory layers (LSTMs), Gated Recurrent Unit (GRU) layers, bidirectional sequential layers, stacking, and Conv1D layers in order to perform sentiment analysis on tweets discussing COVID-19. The goal was to predict which tweets mentioned accurate information about COVID-19 and which tweets mentioned inaccurate or misleading information. There were 8,560 tweets in the dataset, with 52% categorized as “real” and 48% categorized as “fake.”\n",
        "\n",
        "<br>\n",
        "\n",
        "### After training my deep learning models on these authentic tweets, I created artificial tweets - some which stated true facts about COVID-19, and some which stated falsehoods - on which to evaluate the models.\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>1st Model:</u>**\n",
        "\n",
        "### Embedding layer with 32 attributes\n",
        "\n",
        "### 1 LSTM layer with 32 neurons\n",
        "\n",
        "### Batch Size = 32\n",
        "\n",
        "<br>\n",
        "\n",
        "### *Test set metrics:*\n",
        "\n",
        "### Accuracy: 0.9336\n",
        "\n",
        "### F1-score: 0.9364\n",
        "\n",
        "### Precision: 0.9397\n",
        "\n",
        "### Recall: 0.9330\n",
        "\n",
        "### ROC-AUC score: 0.9839\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>2nd Model:</u>**\n",
        "\n",
        "### Embedding layer with 16 attributes\n",
        "\n",
        "### 3 LSTM layers with 32 neurons each, and dropout (0.3) and recurrent dropout (0.3) for each layer\n",
        "\n",
        "### The LSTM layers are bidirectional\n",
        "\n",
        "### Batch Size = 16\n",
        "\n",
        "<br>\n",
        "\n",
        "### *Test set metrics:*\n",
        "\n",
        "### Accuracy: 0.9336\n",
        "\n",
        "### F1-score: 0.9374\n",
        "\n",
        "### Precision: 0.9252\n",
        "\n",
        "### Recall: 0.9500\n",
        "\n",
        "### ROC-AUC score: 0.9847\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>3rd Model:</u>**\n",
        "\n",
        "### Embedding layer with 150 attributes\n",
        "\n",
        "### Conv1D - 32 filters (7x7)\n",
        "\n",
        "### Average Pooling 1D (5x5)\n",
        "\n",
        "### 3 GRU layers with 128 neurons each, and dropout (0.3) and recurrent dropout (0.3) for each layer\n",
        "\n",
        "### Batch Size = 50\n",
        "\n",
        "<br>\n",
        "\n",
        "### *Test set metrics:*\n",
        "\n",
        "### Accuracy: 0.9089\n",
        "\n",
        "### F1-score: 0.9140\n",
        "\n",
        "### Precision: 0.9032\n",
        "\n",
        "### Recall: 0.9250\n",
        "\n",
        "### ROC-AUC score: 0.9676\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>4th Model:</u>**\n",
        "\n",
        "### Embedding layer with 50 attributes\n",
        "\n",
        "### Conv1D - 60 filters (5x5)\n",
        "\n",
        "### Average Pooling ID - (3x3)\n",
        "\n",
        "### 2 GRU layers with 128 neurons each, and dropout (0.2) and recurrent dropout (0.2) for each layer\n",
        "\n",
        "### Batch Size = 20\n",
        "\n",
        "<br>\n",
        "\n",
        "### *Test set metrics:*\n",
        "\n",
        "### Accuracy: 0.9238\n",
        "\n",
        "### F1-score: 0.9275\n",
        "\n",
        "### Precision: 0.9246\n",
        "\n",
        "### Recall: 0.9304\n",
        "\n",
        "### ROC-AUC score: 0.9767\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>5th Model:</u>**\n",
        "\n",
        "### Embedding layer with 26 attributes\n",
        "\n",
        "### 2 LSTM layers with 128 neurons each, and dropout (0.15) and recurrent dropout (0.15) for each layer\n",
        "\n",
        "### 2 GRU layers with 32 neurons each, and dropout (0.15) and recurrent dropout (0.15) for each layer\n",
        "\n",
        "### The LSTM and GRU layers are bidirectional\n",
        "\n",
        "### Batch Size = 32\n",
        "\n",
        "<br>\n",
        "\n",
        "### *Test set metrics:*\n",
        "\n",
        "### Accuracy: 0.9379\n",
        "\n",
        "### F1-score: 0.9411\n",
        "\n",
        "### Precision: 0.9333\n",
        "\n",
        "### Recall: 0.9491\n",
        "\n",
        "### ROC-AUC score: 0.9860\n",
        "\n",
        "<br>\n",
        "\n",
        "### **<u>Best Model:</u>**\n",
        "\n",
        "### As can be seen, my best model in terms of test set metrics, overall, appears to be the fifth model. It achieved the best accuracy, best F1-score, second best precision, second best recall, and the best ROC-AUC score. Its uniqueness stands in stacking two LSTM layers and then stacking two GRU layers, rather than simply stacking layers of the same type together. All of these layers are bidirectional. Further, the model’s embedding layer’s number of attributes is fairly small, at 26.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cgnRjLULyPSQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wH8Af4Le6qs"
      },
      "source": [
        "\n",
        "## **The code below shows a summary of some real and fake COVID-19 tweets in the training set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoqSwgStNzT4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "7e09143a-7647-4686-9f99-af5055385831"
      },
      "source": [
        "#Source:Fighting an Infodemic: COVID-19 Fake News Dataset, https://github.com/diptamath/covid_fake_news,https://arxiv.org/abs/2011.03327\n",
        "\n",
        "import pandas as pd\n",
        "trainingdata=pd.read_csv(\"https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\", usecols = ['tweet','label'])\n",
        "testdata=pd.read_csv(\"https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/english_test_with_labels.csv\", usecols = ['tweet','label'])\n",
        "\n",
        "trainingdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet label\n",
              "0     The CDC currently reports 99031 deaths. In gen...  real\n",
              "1     States reported 1121 deaths a small rise from ...  real\n",
              "2     Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3     #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4     Populous states can generate large case counts...  real\n",
              "...                                                 ...   ...\n",
              "6415  A tiger tested positive for COVID-19 please st...  fake\n",
              "6416  ???Autopsies prove that COVID-19 is??� a blood...  fake\n",
              "6417  _A post claims a COVID-19 vaccine has already ...  fake\n",
              "6418  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund  fake\n",
              "6419  It has been 93 days since the last case of COV...  real\n",
              "\n",
              "[6420 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dda2be7e-c2a0-41f0-a99e-3e01f6241687\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6415</th>\n",
              "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6419</th>\n",
              "      <td>It has been 93 days since the last case of COV...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6420 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dda2be7e-c2a0-41f0-a99e-3e01f6241687')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dda2be7e-c2a0-41f0-a99e-3e01f6241687 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dda2be7e-c2a0-41f0-a99e-3e01f6241687');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c40cb58-b805-4069-be96-e0928eb4574b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c40cb58-b805-4069-be96-e0928eb4574b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c40cb58-b805-4069-be96-e0928eb4574b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_16c632ed-9198-4e36-b3f8-b36879c041a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('trainingdata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16c632ed-9198-4e36-b3f8-b36879c041a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('trainingdata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "trainingdata",
              "summary": "{\n  \"name\": \"trainingdata\",\n  \"rows\": 6420,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6420,\n        \"samples\": [\n          \"Canada\\u2019s top BDSM doctor says wear a mask, leash, tight leather to prevent spread of COVID-19 #cdnpoli #COVID19 https://t.co/1E7yDlIGBD https://t.co/bffEps28Iy\",\n          \"There are 3 cases considered to have recovered from COVID-19 so our total number of active cases is 23 \\u2013 all remain in quarantine facilities.\\u200b \\u200b Our total number of confirmed cases remains at 1192 which is the number we report to the World Health Organization.\",\n          \"Heard about contact tracing but not sure what it is? It\\u2019s used by health departments to prevent the spread of #COVID19. Learn more: https://t.co/J3Txu3riWr. #SlowtheSpread https://t.co/3f8aEQCTuI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fake\",\n          \"real\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfH2uzs2reBK"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Discussion of the dataset in general terms, and why building a predictive model using this data might be practically useful:**\n",
        "\n",
        "### The dataset contains 8,560 tweets that have previously been labelled as either \"real\" (i.e., true) or \"fake\" (i.e., incorrect/misleading). As seen from the results of the code below, there are 3,360 \"real\" tweets in the training set, and 1,120 in the test set. Further, there are 3,060 \"fake\" tweets in the training set, and 1,020 in the test set. Thus, 52% of the data are real tweets and 48% are fake tweets.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Building a highly accurate and predictively strong model based on this data could be very beneficial for helping Twitter (now X) to identify and remove tweets that are misleading/false regarding COVID-19, and thus pose a strong potential health threat to viewers and those to whom they may communicate misinformation learned from Twitter.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Monitoring when spikes in fake tweets are occuring by using such a model could also help health professionals who have access to Twitter to know to move quickly to counter misinformation by speading accurrate tweets in hopes that far more Twitter users will be exposed to correct information about COVID-19 than fake information. Thus, Twitter (now X), the general population of Twitter users, and those with whom Twitter users share information about COVID-19 would stand to benefit from such a model.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Teh6gr2ivqxD",
        "outputId": "1575cb7f-a40e-4d20-c179-a4edf9e1563f"
      },
      "source": [
        "print(len(trainingdata[trainingdata['label'] == 'real']))\n",
        "print(len(testdata[testdata['label'] == 'real']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3360\n",
            "1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS0sEf_hxD7Q",
        "outputId": "40ce0bca-e378-44ea-d470-dc0554180ecf"
      },
      "source": [
        "print(len(trainingdata[trainingdata['label'] == 'fake']))\n",
        "print(len(testdata[testdata['label'] == 'fake']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3060\n",
            "1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbsEn4hy1d5"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "## Define Preprocessor & Prepare Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, LSTM, GRU, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer(num_words=25000)\n",
        "tokenizer.fit_on_texts(trainingdata.tweet)\n",
        "\n",
        "def preprocessor(data, maxlen):\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "    return X\n",
        "\n",
        "X_train = preprocessor(trainingdata.tweet, maxlen=45)\n",
        "X_test = preprocessor(testdata.tweet, maxlen=45)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = pd.get_dummies(trainingdata.label)\n",
        "y_test = pd.get_dummies(testdata.label)"
      ],
      "metadata": {
        "id": "ys5CyXnTlJhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgP4-b463nQ0",
        "outputId": "02dbb91c-734d-425f-9fb2-6535573c0308"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6420, 45)\n",
            "(2140, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "### By running the following code, we can confirm the 'fake' class takes the 0 (first) index position and that the 'real' class takes the 1 (second) index position. This will be helpful when we make actual predictions on unseen data near the end of this project."
      ],
      "metadata": {
        "id": "3XGDOcPAnLGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMe4tIhcnFZd",
        "outputId": "801ac8b7-cd4e-44c4-f274-31f7f50868f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fake', 'real'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiHkYyb0fgmO"
      },
      "source": [
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## Model 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gep1hEGL1Jg4",
        "outputId": "f8307131-1b15-41ce-89a2-600626c4f02b"
      },
      "source": [
        "# Model architecture\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model_1 = Sequential()\n",
        "    model_1.add(Embedding(25000, 32))  # Removed input_length\n",
        "    model_1.add(LSTM(32, return_sequences=True))\n",
        "    model_1.add(Flatten())\n",
        "    model_1.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Callbacks\n",
        "    mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    red_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.05)\n",
        "\n",
        "    # Compile model with updated accuracy metric and optimizer\n",
        "    model_1.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    history = model_1.fit(X_train, y_train, epochs=20, batch_size=32, callbacks=[mc, red_lr], validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m156/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4810\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89642, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7599 - loss: 0.4766 - val_accuracy: 0.8964 - val_loss: 0.2581 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m157/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9265 - loss: 0.1773\n",
            "Epoch 2: val_accuracy improved from 0.89642 to 0.92056, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9267 - loss: 0.1770 - val_accuracy: 0.9206 - val_loss: 0.2074 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m159/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9580 - loss: 0.1039\n",
            "Epoch 3: val_accuracy improved from 0.92056 to 0.92445, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.1038 - val_accuracy: 0.9245 - val_loss: 0.1990 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m153/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0580\n",
            "Epoch 4: val_accuracy did not improve from 0.92445\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0579 - val_accuracy: 0.9229 - val_loss: 0.2283 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m155/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9874 - loss: 0.0315\n",
            "Epoch 5: val_accuracy did not improve from 0.92445\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0316 - val_accuracy: 0.9182 - val_loss: 0.2415 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0180\n",
            "Epoch 6: val_accuracy improved from 0.92445 to 0.92991, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0180 - val_accuracy: 0.9299 - val_loss: 0.2549 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m156/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0130\n",
            "Epoch 7: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0130 - val_accuracy: 0.9283 - val_loss: 0.2829 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m151/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0121\n",
            "Epoch 8: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0121 - val_accuracy: 0.9283 - val_loss: 0.2925 - learning_rate: 5.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0089\n",
            "Epoch 9: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0089 - val_accuracy: 0.9283 - val_loss: 0.2934 - learning_rate: 2.5000e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m152/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0132\n",
            "Epoch 10: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0131 - val_accuracy: 0.9283 - val_loss: 0.2945 - learning_rate: 2.5000e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m160/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0121\n",
            "Epoch 11: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0121 - val_accuracy: 0.9283 - val_loss: 0.2945 - learning_rate: 1.2500e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m159/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0107\n",
            "Epoch 12: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0107 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 1.2500e-07\n",
            "Epoch 13/20\n",
            "\u001b[1m158/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0130\n",
            "Epoch 13: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 6.2500e-09\n",
            "Epoch 14/20\n",
            "\u001b[1m153/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0094\n",
            "Epoch 14: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.1250002585636594e-10.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 6.2500e-09\n",
            "Epoch 15/20\n",
            "\u001b[1m158/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0153\n",
            "Epoch 15: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0152 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 3.1250e-10\n",
            "Epoch 16/20\n",
            "\u001b[1m157/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0109\n",
            "Epoch 16: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625001292818297e-11.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 3.1250e-10\n",
            "Epoch 17/20\n",
            "\u001b[1m153/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0113\n",
            "Epoch 17: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0113 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 1.5625e-11\n",
            "Epoch 18/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0091\n",
            "Epoch 18: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.812500646409148e-13.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 1.5625e-11\n",
            "Epoch 19/20\n",
            "\u001b[1m156/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0080\n",
            "Epoch 19: val_accuracy did not improve from 0.92991\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0081 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 7.8125e-13\n",
            "Epoch 20/20\n",
            "\u001b[1m156/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0091\n",
            "Epoch 20: val_accuracy did not improve from 0.92991\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.906250323204574e-14.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0091 - val_accuracy: 0.9283 - val_loss: 0.2946 - learning_rate: 7.8125e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(model_1, open('model_1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "xWAO6P2B4ALT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = pickle.load(open('model_1.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "LeXA8g3t4ALV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions as labels\n",
        "y_pred = model_1.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = y_test.idxmax(axis=1)\n",
        "\n",
        "# Compute metrics for binary classification\n",
        "# Specify the positive label explicitly\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label='real')\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label='real')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label='real')\n",
        "\n",
        "# Indicate that 'real' is the positive class for calculating the ROC-AUC\n",
        "roc_auc = roc_auc_score((true_labels == 'real').astype(int), model_1.predict(X_test)[:, 1])\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"ROC-AUC score: {:.4f}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjPpmG5iFSz5",
        "outputId": "15b6c04c-a00d-47a9-8eeb-611ee2f1a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Accuracy: 0.9336\n",
            "F1-score: 0.9364\n",
            "Precision: 0.9397\n",
            "Recall: 0.9330\n",
            "ROC-AUC score: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGCSr6Ja36xu"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "## Model 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8EJqRIE36xy",
        "outputId": "1e2832c4-1548-40d0-d84e-d465a0bedec2"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(Embedding(25000, 16))\n",
        "  model_2.add(Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "  model_2.add(Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "  model_2.add(Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.3)))\n",
        "  model_2.add(Flatten())\n",
        "  model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  red_lr= ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.1)\n",
        "\n",
        "  model_2.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model_2.fit(X_train, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=16,\n",
        "                      callbacks=[mc, red_lr],\n",
        "                      validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.7322 - loss: 0.5049\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89408, saving model to best_model.keras\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 288ms/step - accuracy: 0.7325 - loss: 0.5045 - val_accuracy: 0.8941 - val_loss: 0.2578 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9215 - loss: 0.2072\n",
            "Epoch 2: val_accuracy improved from 0.89408 to 0.91355, saving model to best_model.keras\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 286ms/step - accuracy: 0.9215 - loss: 0.2072 - val_accuracy: 0.9136 - val_loss: 0.2030 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9527 - loss: 0.1367\n",
            "Epoch 3: val_accuracy improved from 0.91355 to 0.92290, saving model to best_model.keras\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 288ms/step - accuracy: 0.9527 - loss: 0.1367 - val_accuracy: 0.9229 - val_loss: 0.2034 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9647 - loss: 0.1013\n",
            "Epoch 4: val_accuracy did not improve from 0.92290\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 275ms/step - accuracy: 0.9647 - loss: 0.1013 - val_accuracy: 0.9229 - val_loss: 0.2199 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9716 - loss: 0.0884\n",
            "Epoch 5: val_accuracy did not improve from 0.92290\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 274ms/step - accuracy: 0.9716 - loss: 0.0884 - val_accuracy: 0.9198 - val_loss: 0.2725 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9854 - loss: 0.0442\n",
            "Epoch 6: val_accuracy improved from 0.92290 to 0.92601, saving model to best_model.keras\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 273ms/step - accuracy: 0.9854 - loss: 0.0442 - val_accuracy: 0.9260 - val_loss: 0.2530 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9846 - loss: 0.0426\n",
            "Epoch 7: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 271ms/step - accuracy: 0.9846 - loss: 0.0426 - val_accuracy: 0.9229 - val_loss: 0.2623 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9825 - loss: 0.0554\n",
            "Epoch 8: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 269ms/step - accuracy: 0.9825 - loss: 0.0554 - val_accuracy: 0.9237 - val_loss: 0.2680 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9844 - loss: 0.0489\n",
            "Epoch 9: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 270ms/step - accuracy: 0.9844 - loss: 0.0488 - val_accuracy: 0.9252 - val_loss: 0.2693 - learning_rate: 1.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9891 - loss: 0.0368\n",
            "Epoch 10: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 270ms/step - accuracy: 0.9891 - loss: 0.0368 - val_accuracy: 0.9229 - val_loss: 0.2704 - learning_rate: 1.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9890 - loss: 0.0406\n",
            "Epoch 11: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 271ms/step - accuracy: 0.9890 - loss: 0.0406 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-06\n",
            "Epoch 12/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9888 - loss: 0.0341\n",
            "Epoch 12: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 267ms/step - accuracy: 0.9888 - loss: 0.0341 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-06\n",
            "Epoch 13/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9885 - loss: 0.0368\n",
            "Epoch 13: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 272ms/step - accuracy: 0.9885 - loss: 0.0368 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-07\n",
            "Epoch 14/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9879 - loss: 0.0415\n",
            "Epoch 14: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 275ms/step - accuracy: 0.9879 - loss: 0.0415 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-07\n",
            "Epoch 15/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9855 - loss: 0.0464\n",
            "Epoch 15: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 273ms/step - accuracy: 0.9855 - loss: 0.0463 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-08\n",
            "Epoch 16/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9876 - loss: 0.0364\n",
            "Epoch 16: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 274ms/step - accuracy: 0.9876 - loss: 0.0365 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-08\n",
            "Epoch 17/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9852 - loss: 0.0464\n",
            "Epoch 17: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 275ms/step - accuracy: 0.9852 - loss: 0.0464 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-09\n",
            "Epoch 18/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9894 - loss: 0.0362\n",
            "Epoch 18: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 318ms/step - accuracy: 0.9894 - loss: 0.0362 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-09\n",
            "Epoch 19/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9870 - loss: 0.0426\n",
            "Epoch 19: val_accuracy did not improve from 0.92601\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 274ms/step - accuracy: 0.9870 - loss: 0.0426 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-10\n",
            "Epoch 20/20\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9851 - loss: 0.0397\n",
            "Epoch 20: val_accuracy did not improve from 0.92601\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 270ms/step - accuracy: 0.9851 - loss: 0.0397 - val_accuracy: 0.9229 - val_loss: 0.2703 - learning_rate: 1.0000e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_2, open('model_2.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "dY-mg2Bn3TIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = pickle.load(open('model_2.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "t5ihNwwJ3TIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions as labels\n",
        "y_pred = model_2.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = y_test.idxmax(axis=1)\n",
        "\n",
        "# Compute metrics for binary classification\n",
        "# Specify the positive label explicitly\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label='real')\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label='real')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label='real')\n",
        "\n",
        "# Indicate that 'real' is the positive class for calculating the ROC-AUC\n",
        "roc_auc = roc_auc_score((true_labels == 'real').astype(int), model_2.predict(X_test)[:, 1])\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"ROC-AUC score: {:.4f}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d05b2c7-eb67-4140-98ac-e9ea85b20217",
        "id": "b3769V0Vw_Yk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step\n",
            "Accuracy: 0.9336\n",
            "F1-score: 0.9374\n",
            "Precision: 0.9252\n",
            "Recall: 0.9500\n",
            "ROC-AUC score: 0.9847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpLPokkEHrj3"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "## Model 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8nVsPtsHrj6",
        "outputId": "47e1fcd3-c3c8-4b09-a13c-fc3dceda50ad"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model_3 = Sequential()\n",
        "  model_3.add(layers.Embedding(25000, 150))\n",
        "  model_3.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "  model_3.add(layers.AveragePooling1D(5))\n",
        "  model_3.add(layers.GRU(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "  model_3.add(layers.GRU(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "  model_3.add(layers.GRU(128, dropout=0.3, recurrent_dropout=0.3))\n",
        "  model_3.add(Flatten())\n",
        "  model_3.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "  mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  red_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.05)\n",
        "\n",
        "  model_3.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model_3.fit(X_train, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=50,\n",
        "                      callbacks=[mc,red_lr],\n",
        "                      validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7086 - loss: 0.5588\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88162, saving model to best_model.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.7093 - loss: 0.5578 - val_accuracy: 0.8816 - val_loss: 0.3193 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9109 - loss: 0.2373\n",
            "Epoch 2: val_accuracy improved from 0.88162 to 0.90031, saving model to best_model.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9110 - loss: 0.2371 - val_accuracy: 0.9003 - val_loss: 0.2690 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9550 - loss: 0.1210\n",
            "Epoch 3: val_accuracy did not improve from 0.90031\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.9550 - loss: 0.1210 - val_accuracy: 0.8964 - val_loss: 0.2757 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9782 - loss: 0.0612\n",
            "Epoch 4: val_accuracy did not improve from 0.90031\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9782 - loss: 0.0613 - val_accuracy: 0.9003 - val_loss: 0.2989 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9927 - loss: 0.0278\n",
            "Epoch 5: val_accuracy improved from 0.90031 to 0.90109, saving model to best_model.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - accuracy: 0.9926 - loss: 0.0279 - val_accuracy: 0.9011 - val_loss: 0.3087 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9908 - loss: 0.0317\n",
            "Epoch 6: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9908 - loss: 0.0317 - val_accuracy: 0.9003 - val_loss: 0.3200 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9935 - loss: 0.0252\n",
            "Epoch 7: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9935 - loss: 0.0252 - val_accuracy: 0.9003 - val_loss: 0.3287 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9927 - loss: 0.0217\n",
            "Epoch 8: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - accuracy: 0.9927 - loss: 0.0217 - val_accuracy: 0.9003 - val_loss: 0.3293 - learning_rate: 2.5000e-06\n",
            "Epoch 9/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9936 - loss: 0.0213\n",
            "Epoch 9: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9936 - loss: 0.0213 - val_accuracy: 0.9003 - val_loss: 0.3298 - learning_rate: 2.5000e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9924 - loss: 0.0250\n",
            "Epoch 10: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9924 - loss: 0.0250 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 1.2500e-07\n",
            "Epoch 11/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9927 - loss: 0.0190\n",
            "Epoch 11: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9927 - loss: 0.0191 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 1.2500e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9906 - loss: 0.0276\n",
            "Epoch 12: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9906 - loss: 0.0275 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 6.2500e-09\n",
            "Epoch 13/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9954 - loss: 0.0192\n",
            "Epoch 13: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.1250002585636594e-10.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.9954 - loss: 0.0193 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 6.2500e-09\n",
            "Epoch 14/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9922 - loss: 0.0283\n",
            "Epoch 14: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9923 - loss: 0.0283 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 3.1250e-10\n",
            "Epoch 15/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9929 - loss: 0.0232\n",
            "Epoch 15: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.5625001292818297e-11.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9929 - loss: 0.0232 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 3.1250e-10\n",
            "Epoch 16/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - loss: 0.0187\n",
            "Epoch 16: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9946 - loss: 0.0188 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 1.5625e-11\n",
            "Epoch 17/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9948 - loss: 0.0208\n",
            "Epoch 17: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.812500646409148e-13.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.9948 - loss: 0.0208 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 1.5625e-11\n",
            "Epoch 18/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9922 - loss: 0.0234\n",
            "Epoch 18: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9922 - loss: 0.0234 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 7.8125e-13\n",
            "Epoch 19/20\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9934 - loss: 0.0216\n",
            "Epoch 19: val_accuracy did not improve from 0.90109\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.906250323204574e-14.\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.9934 - loss: 0.0216 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 7.8125e-13\n",
            "Epoch 20/20\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9941 - loss: 0.0201\n",
            "Epoch 20: val_accuracy did not improve from 0.90109\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9940 - loss: 0.0201 - val_accuracy: 0.9003 - val_loss: 0.3299 - learning_rate: 3.9063e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_3, open('model_3.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "iZn2LkKd10Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = pickle.load(open('model_3.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "e9ch9bOA2Y6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions as labels\n",
        "y_pred = model_3.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = y_test.idxmax(axis=1)\n",
        "\n",
        "# Compute metrics for binary classification\n",
        "# Specify the positive label explicitly\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label='real')\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label='real')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label='real')\n",
        "\n",
        "# Indicate that 'real' is the positive class for calculating the ROC-AUC\n",
        "roc_auc = roc_auc_score((true_labels == 'real').astype(int), model_3.predict(X_test)[:, 1])\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"ROC-AUC score: {:.4f}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW6Jd0h-FPLe",
        "outputId": "ac1fa583-8c40-485f-c7f2-a6899a2a093a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Accuracy: 0.9089\n",
            "F1-score: 0.9140\n",
            "Precision: 0.9032\n",
            "Recall: 0.9250\n",
            "ROC-AUC score: 0.9676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLPatMTuTiR7"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "## Model 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmALQmeqTiSF",
        "outputId": "ba9af49a-7309-48b4-a059-5dc75f1353da"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model_4 = Sequential()\n",
        "  model_4.add(layers.Embedding(25000, 50))\n",
        "  model_4.add(layers.Conv1D(60, 5, activation='relu'))\n",
        "  model_4.add(layers.AveragePooling1D(3))\n",
        "  model_4.add(layers.GRU(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "  model_4.add(layers.GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model_4.add(Flatten())\n",
        "  model_4.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "  mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  red_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.05)\n",
        "\n",
        "  model_4.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model_4.fit(X_train, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=20,\n",
        "                      callbacks=[mc,red_lr],\n",
        "                      validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7807 - loss: 0.4483\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90810, saving model to best_model.keras\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - accuracy: 0.7810 - loss: 0.4479 - val_accuracy: 0.9081 - val_loss: 0.2685 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9507 - loss: 0.1416\n",
            "Epoch 2: val_accuracy improved from 0.90810 to 0.91978, saving model to best_model.keras\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - accuracy: 0.9507 - loss: 0.1416 - val_accuracy: 0.9198 - val_loss: 0.2090 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9732 - loss: 0.0707\n",
            "Epoch 3: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.9732 - loss: 0.0708 - val_accuracy: 0.9120 - val_loss: 0.2123 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9801 - loss: 0.0517\n",
            "Epoch 4: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - accuracy: 0.9801 - loss: 0.0517 - val_accuracy: 0.9104 - val_loss: 0.2572 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9922 - loss: 0.0268\n",
            "Epoch 5: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - accuracy: 0.9922 - loss: 0.0268 - val_accuracy: 0.9143 - val_loss: 0.2421 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9927 - loss: 0.0202\n",
            "Epoch 6: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 65ms/step - accuracy: 0.9927 - loss: 0.0202 - val_accuracy: 0.9182 - val_loss: 0.2478 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9938 - loss: 0.0195\n",
            "Epoch 7: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - accuracy: 0.9938 - loss: 0.0195 - val_accuracy: 0.9182 - val_loss: 0.2477 - learning_rate: 2.5000e-06\n",
            "Epoch 8/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9933 - loss: 0.0205\n",
            "Epoch 8: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9933 - loss: 0.0205 - val_accuracy: 0.9182 - val_loss: 0.2478 - learning_rate: 2.5000e-06\n",
            "Epoch 9/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9949 - loss: 0.0149\n",
            "Epoch 9: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - accuracy: 0.9949 - loss: 0.0150 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 1.2500e-07\n",
            "Epoch 10/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9940 - loss: 0.0194\n",
            "Epoch 10: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9940 - loss: 0.0194 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 1.2500e-07\n",
            "Epoch 11/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9948 - loss: 0.0192\n",
            "Epoch 11: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - accuracy: 0.9948 - loss: 0.0192 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 6.2500e-09\n",
            "Epoch 12/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9949 - loss: 0.0184\n",
            "Epoch 12: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.1250002585636594e-10.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - accuracy: 0.9949 - loss: 0.0184 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 6.2500e-09\n",
            "Epoch 13/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9926 - loss: 0.0208\n",
            "Epoch 13: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.9926 - loss: 0.0208 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 3.1250e-10\n",
            "Epoch 14/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9934 - loss: 0.0209\n",
            "Epoch 14: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.5625001292818297e-11.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - accuracy: 0.9934 - loss: 0.0209 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 3.1250e-10\n",
            "Epoch 15/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9925 - loss: 0.0191\n",
            "Epoch 15: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 65ms/step - accuracy: 0.9925 - loss: 0.0191 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 1.5625e-11\n",
            "Epoch 16/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9961 - loss: 0.0131\n",
            "Epoch 16: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.812500646409148e-13.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - accuracy: 0.9961 - loss: 0.0131 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 1.5625e-11\n",
            "Epoch 17/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9932 - loss: 0.0190\n",
            "Epoch 17: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - accuracy: 0.9932 - loss: 0.0190 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 7.8125e-13\n",
            "Epoch 18/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9941 - loss: 0.0172\n",
            "Epoch 18: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.906250323204574e-14.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 7.8125e-13\n",
            "Epoch 19/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9946 - loss: 0.0169\n",
            "Epoch 19: val_accuracy did not improve from 0.91978\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 0.9946 - loss: 0.0169 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 3.9063e-14\n",
            "Epoch 20/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9936 - loss: 0.0175\n",
            "Epoch 20: val_accuracy did not improve from 0.91978\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.9531251616022873e-15.\n",
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9936 - loss: 0.0175 - val_accuracy: 0.9182 - val_loss: 0.2479 - learning_rate: 3.9063e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_4, open('model_4.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "90-rqU-C2rPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = pickle.load(open('model_4.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "gLbJdKlK2rPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions as labels\n",
        "y_pred = model_4.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = y_test.idxmax(axis=1)\n",
        "\n",
        "# Compute metrics for binary classification\n",
        "# Specify the positive label explicitly\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label='real')\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label='real')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label='real')\n",
        "\n",
        "# Indicate that 'real' is the positive class for calculating the ROC-AUC\n",
        "roc_auc = roc_auc_score((true_labels == 'real').astype(int), model_4.predict(X_test)[:, 1])\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"ROC-AUC score: {:.4f}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN1jGRfzFLXH",
        "outputId": "dd0cb00e-c279-46eb-e613-b00a1967b111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Accuracy: 0.9238\n",
            "F1-score: 0.9275\n",
            "Precision: 0.9246\n",
            "Recall: 0.9304\n",
            "ROC-AUC score: 0.9767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5l_nINdBK8r"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "## Model 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4WC6B7kA_D-",
        "outputId": "d37d5fa1-d8cf-4581-8519-0741df3f5d00"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  model_5 = Sequential()\n",
        "  model_5.add(Embedding(25000, 26))\n",
        "  model_5.add(Bidirectional(LSTM(128, dropout=0.15, recurrent_dropout=0.15, return_sequences=True)))\n",
        "  model_5.add(Bidirectional(LSTM(128, dropout=0.15, recurrent_dropout=0.15, return_sequences=True)))\n",
        "  model_5.add(Bidirectional(GRU(32, dropout=0.15, recurrent_dropout=0.15, return_sequences=True)))\n",
        "  model_5.add(Bidirectional(GRU(32, dropout=0.15, recurrent_dropout=0.15)))\n",
        "  model_5.add(Flatten())\n",
        "  model_5.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  red_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.05)\n",
        "\n",
        "  model_5.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model_5.fit(X_train, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks=[mc,red_lr],\n",
        "                      validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - accuracy: 0.7368 - loss: 0.5382\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90732, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 703ms/step - accuracy: 0.7373 - loss: 0.5383 - val_accuracy: 0.9073 - val_loss: 0.2458 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - accuracy: 0.9321 - loss: 0.1991\n",
            "Epoch 2: val_accuracy improved from 0.90732 to 0.91667, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 652ms/step - accuracy: 0.9321 - loss: 0.1993 - val_accuracy: 0.9167 - val_loss: 0.2195 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9535 - loss: 0.1494\n",
            "Epoch 3: val_accuracy did not improve from 0.91667\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 649ms/step - accuracy: 0.9535 - loss: 0.1495 - val_accuracy: 0.9151 - val_loss: 0.2157 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - accuracy: 0.9736 - loss: 0.1048\n",
            "Epoch 4: val_accuracy did not improve from 0.91667\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 654ms/step - accuracy: 0.9736 - loss: 0.1050 - val_accuracy: 0.9159 - val_loss: 0.1913 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9832 - loss: 0.0494\n",
            "Epoch 5: val_accuracy improved from 0.91667 to 0.92368, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 651ms/step - accuracy: 0.9832 - loss: 0.0494 - val_accuracy: 0.9237 - val_loss: 0.1793 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - accuracy: 0.9891 - loss: 0.0370\n",
            "Epoch 6: val_accuracy improved from 0.92368 to 0.92679, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 649ms/step - accuracy: 0.9891 - loss: 0.0370 - val_accuracy: 0.9268 - val_loss: 0.1781 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9895 - loss: 0.0352\n",
            "Epoch 7: val_accuracy improved from 0.92679 to 0.92757, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 649ms/step - accuracy: 0.9895 - loss: 0.0352 - val_accuracy: 0.9276 - val_loss: 0.1852 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.9896 - loss: 0.0317\n",
            "Epoch 8: val_accuracy did not improve from 0.92757\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 654ms/step - accuracy: 0.9896 - loss: 0.0317 - val_accuracy: 0.9229 - val_loss: 0.1861 - learning_rate: 5.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9914 - loss: 0.0306\n",
            "Epoch 9: val_accuracy improved from 0.92757 to 0.92913, saving model to best_model.keras\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 651ms/step - accuracy: 0.9914 - loss: 0.0306 - val_accuracy: 0.9291 - val_loss: 0.1817 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - accuracy: 0.9897 - loss: 0.0355\n",
            "Epoch 10: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 657ms/step - accuracy: 0.9897 - loss: 0.0354 - val_accuracy: 0.9268 - val_loss: 0.1840 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.9922 - loss: 0.0284\n",
            "Epoch 11: val_accuracy did not improve from 0.92913\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 660ms/step - accuracy: 0.9922 - loss: 0.0284 - val_accuracy: 0.9291 - val_loss: 0.1851 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - accuracy: 0.9929 - loss: 0.0213\n",
            "Epoch 12: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 654ms/step - accuracy: 0.9929 - loss: 0.0213 - val_accuracy: 0.9291 - val_loss: 0.1848 - learning_rate: 2.5000e-06\n",
            "Epoch 13/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9925 - loss: 0.0210\n",
            "Epoch 13: val_accuracy did not improve from 0.92913\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 657ms/step - accuracy: 0.9925 - loss: 0.0210 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 2.5000e-06\n",
            "Epoch 14/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - accuracy: 0.9934 - loss: 0.0234\n",
            "Epoch 14: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 648ms/step - accuracy: 0.9934 - loss: 0.0234 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 1.2500e-07\n",
            "Epoch 15/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - accuracy: 0.9912 - loss: 0.0281\n",
            "Epoch 15: val_accuracy did not improve from 0.92913\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 646ms/step - accuracy: 0.9912 - loss: 0.0281 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 1.2500e-07\n",
            "Epoch 16/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.9913 - loss: 0.0278\n",
            "Epoch 16: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 644ms/step - accuracy: 0.9913 - loss: 0.0278 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 6.2500e-09\n",
            "Epoch 17/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9928 - loss: 0.0229\n",
            "Epoch 17: val_accuracy did not improve from 0.92913\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.1250002585636594e-10.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 649ms/step - accuracy: 0.9928 - loss: 0.0229 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 6.2500e-09\n",
            "Epoch 18/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - accuracy: 0.9934 - loss: 0.0306\n",
            "Epoch 18: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 648ms/step - accuracy: 0.9934 - loss: 0.0306 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 3.1250e-10\n",
            "Epoch 19/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9920 - loss: 0.0265\n",
            "Epoch 19: val_accuracy did not improve from 0.92913\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625001292818297e-11.\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 648ms/step - accuracy: 0.9920 - loss: 0.0265 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 3.1250e-10\n",
            "Epoch 20/20\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.9920 - loss: 0.0297\n",
            "Epoch 20: val_accuracy did not improve from 0.92913\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 651ms/step - accuracy: 0.9920 - loss: 0.0297 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 1.5625e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_5, open('model_5.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "wfYTeIu22z-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = pickle.load(open('model_5.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "Lo8DtbsH2z-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "# Generate predictions as labels\n",
        "y_pred = model_5.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = y_test.idxmax(axis=1)\n",
        "\n",
        "# Compute metrics for binary classification\n",
        "# Specify the positive label explicitly\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label='real')\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label='real')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label='real')\n",
        "\n",
        "# Indicate that 'real' is the positive class for calculating the ROC-AUC\n",
        "roc_auc = roc_auc_score((true_labels == 'real').astype(int), model_5.predict(X_test)[:, 1])\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"ROC-AUC score: {:.4f}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2BOFEcBEghX",
        "outputId": "23c2e935-4bda-4330-cc5c-affd6f7f2e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step\n",
            "Accuracy: 0.9379\n",
            "F1-score: 0.9411\n",
            "Precision: 0.9333\n",
            "Recall: 0.9491\n",
            "ROC-AUC score: 0.9860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCCeGHVW-CPT"
      },
      "source": [
        "---\n",
        "\n",
        "## **Discussion of the best and worst performing models:**\n",
        "\n",
        "### All of my models use a keras tokenizer with the num_words argument set to 25000, which restricts the vocabulary size to be considered by the models to the 25,000 most frequently used words in the dataset. All of my models also use the maxlen argument value of 45 in the pad_sequences function in the processor. Since all sequence data in keras deep learning models must contain the same number of tokens to ensure the same length, a maxlen argument value of 45 means that token sequences longer than 45 will be truncated at 45, and all token sequences shorter than 45 will be padded with zeroes.\n",
        "\n",
        "<br>\n",
        "\n",
        "### My 5th model performed the best - overall - on test set data (93.79% accuracy, 0.9411 F1-score, 0.9333 precision, 0.9491 recall, and 0.9860 ROC-AUC score). This model combined two bidirectional LSTM layers (each having 128 neurons) with two bidirectional GRU layers (each having 32 neurons). All of my models used embeddings; in my 5th model, the embedding layer contained 26 attributes. I also used dropout (.15) and recurrent dropout (.15) to try to reduce overfitting. It is possible that in this case the lower percentage for dropout compared to my other models may have contributed towards the higher test set performance, although normally the opposite might be expected.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Model 3 achieved the lowest test set metrics in every category compared to all other models. It used conv1d (32 filters of size 7x7) and average pooling of size 5x5 to decrease the number of parameters before stacking. I then included 3 GRU layers back to back - each having 128 neurons, dropout (0.30), and recurrent dropout (0.30). It is noteable that the larger number of stacked layers, larger number of neurons per layer, and larger proportion of nuerons experiencing dropout compared to the other models did not result in better validation accuracy or better test set performance. This may suggest that with this dataset simpler models perform better. Bigger is not always better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sca3f-v-QFoa"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Using the Best Model for Predictions on Unseen Tweets:**\n",
        "\n",
        "### Below, I have created a series of tweets (5 real and 5 fake), and used model 5 to predict if the tweets contain real or fake information about COVID-19."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmwGJ5nzO6Xm",
        "outputId": "2bd76c0a-3f18-4a04-b197-436113197aa0"
      },
      "source": [
        "# Fake example #1\n",
        "\n",
        "print(model_5.predict(preprocessor([\"COVID is fake news. It's nothing more than the common flu. This is just anti-Trump propoganda from the Radical Left.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "[[9.990910e-01 9.089763e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw8zLpK5Q_N0",
        "outputId": "33795bdc-7c96-455c-cb78-ce7ebe9f4476"
      },
      "source": [
        "# Fake example #2\n",
        "\n",
        "print(model_5.predict(preprocessor([\"COVID-19 is no more deadly than the flu. Don't believe what the 'experts' are telling you. Don't wear a mask if you don't feel like it!\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "[[0.9975681  0.00243191]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srN_AMqyRatw",
        "outputId": "b57add3c-1708-4cd6-e759-608da9dac1bf"
      },
      "source": [
        "# Fake example #3\n",
        "\n",
        "print(model_5.predict(preprocessor([\"Don't let the Antifa radicals convince you that COVID is dangerous. They just want to destroy our economy by making people stay home so that they can steal the election.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "[[0.9967694  0.00323056]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtxYaR0LRiPW",
        "outputId": "60b30fc4-ac1e-44d8-af3e-bca40b9d6042"
      },
      "source": [
        "# Fake example #4\n",
        "\n",
        "print(model_5.predict(preprocessor([\"COVID-19 is China's attempt to take over the world. They have been developing biological weapons for decades to unleash on the US. They will kill their own people to do it if necessary.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "[[0.98120946 0.01879057]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahX6HFfHRj46",
        "outputId": "a40fdfc7-99a4-4663-e2fa-998d378cf368"
      },
      "source": [
        "# Fake example #5\n",
        "\n",
        "print(model_5.predict(preprocessor([\"COVID-19 mRNA is actually not a vaccine at all, but rather an operating system that will convert our bodies into zombies.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "[[0.99219114 0.00780889]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAyv9VIwTIdo",
        "outputId": "57b24424-f249-4ac4-c355-8960a3623288"
      },
      "source": [
        "# Real example #1\n",
        "\n",
        "print(model_5.predict(preprocessor([\"COVID-19 was the 3rd leading cause of death in the US in 2020, with heart disease and cancer being even deadlier.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "[[0.96569633 0.03430365]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekqJo52Idhgj",
        "outputId": "f679540a-0827-4355-bb92-71a61c3cc812"
      },
      "source": [
        "# Real example #2\n",
        "\n",
        "print(model_5.predict(preprocessor([\"There is no evidence to back up the claim that COVID-19 increases the chances of women having miscarriages.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "[[0.98464453 0.01535552]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Rqs3Ppd8CL",
        "outputId": "e9b6328c-e676-418c-83af-ca33fc066a00"
      },
      "source": [
        "# Real example #3\n",
        "\n",
        "print(model_5.predict(preprocessor([\"People with cancer, kidney disease, lung diseases, dementia, diabetes, or liver disease are more likely to become seriously ill from COVID-19.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "[[0.9320307  0.06796932]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfUI9DckenFD",
        "outputId": "0ddfbae1-fb97-43ff-a8ad-71303fd6fe5e"
      },
      "source": [
        "# Real example #4\n",
        "\n",
        "print(model_5.predict(preprocessor([\"Children have been impacted less harmfully by COVID infections, on average, than adults.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "[[0.14142035 0.85857964]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K80IdbNHfHZ2",
        "outputId": "ccacdec7-d441-4993-cc7e-a6f7347b94c6"
      },
      "source": [
        "# Real example #5\n",
        "\n",
        "print(model_5.predict(preprocessor([\"People who have substance abuse problems are more likely to experience severe COVID-19 symtoms, if infected, than those who do not.\"], maxlen=60)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "[[0.16539998 0.8346    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq3TuTExgFyR"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Results:**\n",
        "\n",
        "### Recall that in the predictions above, **0 (the first index position)** corresponds to the **fake** class and that **1 (the second index position)** corresponds to the **real** class.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Since predicted probabilities for accuracy are rounded up for values greater than 0.5, and rounded down for values less than 0.5, the model correctly predicts all 5 of the fake tweets as being fake. However, it only correctly predicts 2 of the 5 real tweets (real examples #4 and #5) as being real. This corresponds to an overall model accuracy level of 70% - at least when tested on my \"unseen\" samples."
      ]
    }
  ]
}